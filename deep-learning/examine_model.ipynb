{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_init:\n",
    "    %pip install -U pip\n",
    "    !if  [ ! -d \"deep-learning-project\" ] ; then git clone https://github.com/albertsgarde/deep-learning-project.git; fi\n",
    "    !cd deep-learning-project && git reset --hard && git pull\n",
    "    !source deep-learning-project/setup.sh deep-learning-project\n",
    "    import os\n",
    "    os.chdir(\"deep-learning-project/deep-learning\")\n",
    "run_init = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_init = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_init = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nn_func\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import IPython.display as display\n",
    "\n",
    "import audio_samples_py as aus\n",
    "\n",
    "import utils.plots as plots\n",
    "import utils.criterion as chord_criterion\n",
    "import utils.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GPU.\n"
     ]
    }
   ],
   "source": [
    "device, use_cuda = utils.setup_device(use_cuda_if_possible = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_LENGTH = 1024\n",
    "BATCH_SIZE = 64\n",
    "SEED = 2 # Generates different data if changed. Useful to ensure that a result isn't a fluke.\n",
    "\n",
    "possible_chord_types = [i for i in range(aus.num_chord_types())]\n",
    "octave_parameters = aus.OctaveParameters(add_root_octave_probability=0.5,\n",
    "        add_other_octave_probability=0.3)\n",
    "parameters = aus.DataParameters(num_samples=SAMPLE_LENGTH, octave_parameters=octave_parameters, min_frequency=50, max_frequency=2000, min_frequency_std_dev=0.5, max_frequency_std_dev=3., possible_chord_types=possible_chord_types) \\\n",
    "    .add_sine(probability=0.5, amplitude_range=(0.1,0.2)) \\\n",
    "    .add_saw(probability=0.5, amplitude_range=(0.1, 0.2)) \\\n",
    "    .add_pulse(probability=0.5, amplitude_range=(0.1, 0.2), duty_cycle_range=(0.1, 0.9)) \\\n",
    "    .add_triangle(probability=0.5, amplitude_range=(0.1, 0.2)) \\\n",
    "    .add_noise(probability=1, amplitude_range=(0.001, 0.04)) \\\n",
    "    .apply_distortion(probability=0.5, power_range=(0.1, 20)) \\\n",
    "    .apply_normalization(probability=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_target(label: aus.DataPointLabel):\n",
    "    \n",
    "    target = np.zeros(aus.num_chord_types() + 12, dtype=np.float32)\n",
    "    target[label.chord_type()] = 1\n",
    "    target[aus.num_chord_types() + label.note()] = 1\n",
    "    return target\n",
    "\n",
    "training_parameters, training_loader, validation_parameters, validation_loader = utils.init_synth_data(parameters, label_to_target, SEED, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.jit.load(\"models/model1_1024_80000.pt\")\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_header = [\"Base.Freq\", \"Min.Freq\", \"Max.Freq\", \"Tone\", \"Type\", \"Acc.Type\", \"Acc.Tone\", \"Acc\", \"Out.Type\", \"Out.Tone\"]\n",
    "\n",
    "def build_data_row(label: aus.DataPointLabel, output, target):\n",
    "    if label.frequencies():\n",
    "        frequencies = label.frequencies()\n",
    "        min_frequency = min(frequencies)\n",
    "        max_frequency = max(frequencies)\n",
    "    else:\n",
    "        min_frequency = None\n",
    "        max_frequency = None\n",
    "    \n",
    "    output_chord_type = np.argmax(output[:aus.num_chord_types()])\n",
    "    output_chord_tone = np.argmax(output[aus.num_chord_types():])\n",
    "    accurate_chord_type = output_chord_type == label.chord_type()\n",
    "    accurate_chord_tone = output_chord_tone == label.note()\n",
    "    accurate = accurate_chord_type and accurate_chord_tone\n",
    "    \n",
    "\n",
    "    return [label.frequency(), min_frequency, max_frequency, label.note(), label.chord_type_name(), accurate_chord_type, accurate_chord_tone, accurate, output_chord_type, output_chord_tone]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = chord_criterion.ChordToneLoss(aus.num_chord_types())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: line_profiler in c:\\users\\alber\\anaconda3\\envs\\torch-notebook\\lib\\site-packages (4.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%pip install line_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 100\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\anaconda3\\envs\\torch-notebook\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190: UserWarning: FALLBACK path has been taken inside: torch::jit::fuser::cuda::runCudaFusionGroup. This is an indication that codegen Failed for some reason.\n",
      "To debug try disable codegen fallback path via setting the env variable `export PYTORCH_NVFUSER_DISABLE=fallback`\n",
      " (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\jit\\codegen\\cuda\\manager.cpp:336.)\n",
      "  return forward_call(*input, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 1200\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [25], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m#%lprun -f eval eval()\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[39meval\u001b[39;49m()\n",
      "Cell \u001b[1;32mIn [25], line 18\u001b[0m, in \u001b[0;36meval\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batch_signal\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m     17\u001b[0m     label \u001b[39m=\u001b[39m batch_labels[i]\n\u001b[1;32m---> 18\u001b[0m     target \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mto_numpy(batch_target[i,:])\n\u001b[0;32m     19\u001b[0m     output \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mto_numpy(batch_output[i,:])\n\u001b[0;32m     21\u001b[0m     data_row \u001b[39m=\u001b[39m build_data_row(label, output, target) \n",
      "File \u001b[1;32mc:\\Users\\alber\\Google Drive\\DTU\\Deep Learning\\project\\deep-learning\\utils\\utils.py:29\u001b[0m, in \u001b[0;36mto_numpy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m     28\u001b[0m     \u001b[39mif\u001b[39;00m use_cuda:\n\u001b[1;32m---> 29\u001b[0m         \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     31\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_DATA_POINTS = 100000\n",
    "PRINT_PROGRESS_EVERY = 100\n",
    "OUTPUT_PATH = \"eval_data.csv\"\n",
    "\n",
    "data = []\n",
    "\n",
    "net.eval()\n",
    "def eval():\n",
    "    for batch_signal, batch_fft, batch_target, batch_labels in utils.cycle_data_loader(training_loader):\n",
    "        batch_signal = utils.to_torch(batch_signal)\n",
    "        batch_fft = utils.to_torch(batch_fft)\n",
    "        batch_target = utils.to_torch(batch_target)\n",
    "        batch_output = net(batch_signal, batch_fft)\n",
    "\n",
    "        for i in range(batch_signal.shape[0]):\n",
    "\n",
    "            label = batch_labels[i]\n",
    "            target = utils.to_numpy(batch_target[i,:])\n",
    "            output = utils.to_numpy(batch_output[i,:])\n",
    "            \n",
    "            data_row = build_data_row(label, output, target) \n",
    "            data.append(data_row)\n",
    "\n",
    "            if len(data) % PRINT_PROGRESS_EVERY == 0:\n",
    "                print(f\"Processed: {len(data)}\", end=\"\\r\")\n",
    "            if len(data) >= NUM_DATA_POINTS:\n",
    "                break\n",
    "        if len(data) >= NUM_DATA_POINTS:\n",
    "            break\n",
    "#%lprun -f eval eval()\n",
    "eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(OUTPUT_PATH, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(data_header)\n",
    "    writer.writerows(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('torch-notebook')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34fdfbbea481bd85da6d3a89cefc0eac7829bd3d33c7e2764c66b35aab7d912a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
