{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_init:\n",
    "    %pip install -U pip\n",
    "    !if  [ ! -d \"deep-learning-project\" ] ; then git clone https://github.com/albertsgarde/deep-learning-project.git; fi\n",
    "    !cd deep-learning-project && git reset --hard && git pull\n",
    "    !source deep-learning-project/setup.sh deep-learning-project\n",
    "    import os\n",
    "    os.chdir(\"deep-learning-project/deep-learning\")\n",
    "run_init = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_init = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_init = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nn_func\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import IPython.display as display\n",
    "\n",
    "import audio_samples_py as aus\n",
    "\n",
    "import utils.plots as plots\n",
    "import utils.criterion as chord_criterion\n",
    "import utils.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device, use_cuda = utils.setup_device(use_cuda_if_possible = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_LENGTH = 1024\n",
    "BATCH_SIZE = 64\n",
    "SEED = 2 # Generates different data if changed. Useful to ensure that a result isn't a fluke.\n",
    "\n",
    "possible_chord_types = [i for i in range(aus.num_chord_types())]\n",
    "octave_parameters = aus.OctaveParameters(add_root_octave_probability=0.5,\n",
    "        add_other_octave_probability=0.3)\n",
    "parameters = aus.DataParameters(num_samples=SAMPLE_LENGTH, octave_parameters=octave_parameters, min_frequency=50, max_frequency=2000, min_frequency_std_dev=0.5, max_frequency_std_dev=3., possible_chord_types=possible_chord_types) \\\n",
    "    .add_sine(probability=0.5, amplitude_range=(0.1,0.2)) \\\n",
    "    .add_saw(probability=0.5, amplitude_range=(0.1, 0.2)) \\\n",
    "    .add_pulse(probability=0.5, amplitude_range=(0.1, 0.2), duty_cycle_range=(0.1, 0.9)) \\\n",
    "    .add_triangle(probability=0.5, amplitude_range=(0.1, 0.2)) \\\n",
    "    .add_noise(probability=1, amplitude_range=(0.001, 0.04)) \\\n",
    "    .apply_distortion(probability=0.5, power_range=(0.1, 20)) \\\n",
    "    .apply_normalization(probability=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_target(label: aus.DataPointLabel):\n",
    "    \n",
    "    target = np.zeros(aus.num_chord_types() + 12, dtype=np.float32)\n",
    "    target[label.chord_type()] = 1\n",
    "    target[aus.num_chord_types() + label.note()] = 1\n",
    "    return target\n",
    "\n",
    "training_parameters, training_loader, validation_parameters, validation_loader = utils.init_synth_data(parameters, label_to_target, SEED, BATCH_SIZE)\n",
    "rw_training_loader, rw_validation_loader = utils.init_rw_data(\"data/short_guitar_samples/\", label_to_target, 0.5, BATCH_SIZE, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.jit.load(\"C:/Users/alber/Google Drive/DTU/Deep Learning/data/rw_only_model11.pt\")\n",
    "#net = torch.jit.load(\"C:/Users/alber/Google Drive/DTU/Deep Learning/data/rw_model3_400k_c.pt\")\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_header = [\"Tone\", \"Type\", \"Out Tone\", \"Out Type\", \"Acc.Type\", \"Acc.Tone\", \"Acc\"]\n",
    "\n",
    "tone_names = [\"A\",\"Bb\", \"B\", \"C\", \"Db\", \"D\", \"Eb\", \"E\", \"F\", \"Gb\", \"G\", \"Ab\"]\n",
    "\n",
    "def build_data_row(label: aus.DataPointLabel, output, target):\n",
    "    if label.frequencies():\n",
    "        frequencies = label.frequencies()\n",
    "        min_frequency = min(frequencies)\n",
    "        max_frequency = max(frequencies)\n",
    "    else:\n",
    "        min_frequency = None\n",
    "        max_frequency = None\n",
    "    \n",
    "    output_chord_type = np.argmax(output[:aus.num_chord_types()])\n",
    "    output_chord_tone = np.argmax(output[aus.num_chord_types():])\n",
    "    accurate_chord_type = output_chord_type == label.chord_type()\n",
    "    accurate_chord_tone = output_chord_tone == label.note()\n",
    "    accurate = accurate_chord_type and accurate_chord_tone\n",
    "    \n",
    "\n",
    "    return [tone_names[label.note()], label.chord_type_name(), tone_names[output_chord_tone], aus.chord_type_name(output_chord_type), accurate_chord_type, accurate_chord_tone, accurate]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = chord_criterion.ChordToneLoss(aus.num_chord_types())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DATA_POINTS = 10_000\n",
    "PRINT_PROGRESS_EVERY = 100\n",
    "OUTPUT_PATH = \"eval_data.csv\"\n",
    "\n",
    "data = []\n",
    "\n",
    "net.eval()\n",
    "def eval():\n",
    "    for batch_signal, batch_fft, batch_target, batch_labels in rw_validation_loader:\n",
    "        batch_signal = utils.to_torch(batch_signal)\n",
    "        batch_fft = utils.to_torch(batch_fft)\n",
    "        batch_target = utils.to_torch(batch_target)\n",
    "        batch_output = net(batch_signal, batch_fft)\n",
    "\n",
    "        for i in range(batch_signal.shape[0]):\n",
    "\n",
    "            label = batch_labels[i]\n",
    "            target = utils.to_numpy(batch_target[i,:])\n",
    "            output = utils.to_numpy(batch_output[i,:])\n",
    "            \n",
    "            data_row = build_data_row(label, output, target) \n",
    "            data.append(data_row)\n",
    "\n",
    "            print(f\"Processed: {len(data)}\", end=\"\\r\")\n",
    "            if len(data) >= NUM_DATA_POINTS:\n",
    "                break\n",
    "        if len(data) >= NUM_DATA_POINTS:\n",
    "            break\n",
    "eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(OUTPUT_PATH, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(data_header)\n",
    "    writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "DATA_PATH = OUTPUT_PATH\n",
    "\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "\n",
    "chord_count_data = data.copy(deep=True)\n",
    "chord_count_data[\"Chord\"] = chord_count_data[\"Tone\"] + \",\" + chord_count_data[\"Type\"]\n",
    "chord_count_data[\"Out Chord\"] = chord_count_data[\"Out Tone\"] + \",\" + chord_count_data[\"Out Type\"]\n",
    "\n",
    "print(chord_count_data.head())\n",
    "\n",
    "chord_count_data = chord_count_data[[\"Chord\", \"Out Chord\"]] \\\n",
    "    .pipe(pd.pivot_table, index=[\"Chord\"], columns=[\"Out Chord\"], aggfunc=len, fill_value=0)\n",
    "    \n",
    "chord_count_data = chord_count_data.div(chord_count_data.sum(axis=1)/100, axis=\"index\")\n",
    "\n",
    "sns.heatmap(chord_count_data, annot=True, fmt=\".1f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data[(data[\"Tone\"]==\"F\") & (data[\"Type\"] == \"Major\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as plt\n",
    "import csv\n",
    "\n",
    "DATA_PATH = \"C:/Users/alber/Downloads/eval_data.csv\"\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "\n",
    "bins = [50, 70, 100, 200, 500, 1000, 2000]\n",
    "\n",
    "data['binned'] = pd.cut(data['Base.Freq'], bins)\n",
    "print(data.value_counts(subset=['binned'], sort=False))\n",
    "bin_counts = data.value_counts(subset=['binned'], sort=False)\n",
    "#data = data[data[\"Acc\"]]\n",
    "print(bin_counts.tolist())\n",
    "\n",
    "\n",
    "\n",
    "sns.barplot(x=[str(bin) for bin in bins[1:]], y=bin_counts.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('torch-notebook')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34fdfbbea481bd85da6d3a89cefc0eac7829bd3d33c7e2764c66b35aab7d912a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
