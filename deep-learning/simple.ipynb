{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_init:\n",
    "    %pip install -U pip\n",
    "    !if  [ ! -d \"deep-learning-project\" ] ; then git clone https://github.com/albertsgarde/deep-learning-project.git; fi\n",
    "    !cd deep-learning-project && git reset --hard && git pull\n",
    "    !source deep-learning-project/setup.sh deep-learning-project\n",
    "run_init = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_init = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_init = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nn_func\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import audio_samples_py as aus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Running GPU.\") if use_cuda else print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_LENGTH = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "class AudioDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, parameters: aus.DataParameters):\n",
    "         self.parameters = parameters\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.iinfo(np.int64).max\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data_point = self.parameters.generate_at_index(index)\n",
    "        return data_point.get_samples(), torch.tensor([data_point.get_frequency_map()]).unsqueeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_loader_params = {\"batch_size\": 64}\n",
    "\n",
    "parameters = aus.DataParameters(num_samples=SAMPLE_LENGTH).add_sine((0.5,0.75))\n",
    "training_parameters = parameters.with_seed_offset(0)\n",
    "training_generator = aus.DataGenerator(training_parameters)\n",
    "training_loader = torch.utils.data.DataLoader(AudioDataSet(training_parameters), **data_loader_params)\n",
    "validation_parameters = parameters.with_seed_offset(1)\n",
    "validation_generator = aus.DataGenerator(validation_parameters)\n",
    "validation_loader = torch.utils.data.DataLoader(AudioDataSet(validation_parameters), **data_loader_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_depth = 2\n",
    "channels = [8, 8, 8, 8]\n",
    "kernel_sizes = [5, 5, 5, 5]\n",
    "strides = [1 for _ in range(conv_depth)]\n",
    "paddings = [int((kernel_size - 1)/2) for kernel_size in kernel_sizes]\n",
    "poolings = [2,2,2,2]\n",
    "conv_batch_norms = [False for _ in range(conv_depth)]\n",
    "conv_dropouts = [0.0 for _ in range(conv_depth)]\n",
    "\n",
    "\n",
    "lin_depth = 2\n",
    "features = [256, 128]\n",
    "lin_batch_norms = [False for _ in range(lin_depth)]\n",
    "lin_dropouts = [0.0 for _ in range(lin_depth)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter validation and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(channels) >= conv_depth\n",
    "assert len(kernel_sizes) >= conv_depth\n",
    "assert len(strides) >= conv_depth\n",
    "assert len(paddings) >= conv_depth\n",
    "assert len(poolings) >= conv_depth\n",
    "assert len(conv_batch_norms) >= conv_depth\n",
    "assert len(conv_dropouts) >= conv_depth\n",
    "for kernel_size in kernel_sizes:\n",
    "    assert kernel_size % 2 == 1, \"Only odd kernel sizes are supported.\"\n",
    "for dropout in conv_dropouts:\n",
    "    assert 0 <= dropout and dropout <= 1, \"Dropout must be between 0 and 1.\"\n",
    "\n",
    "conv_size = []\n",
    "input_size = SAMPLE_LENGTH\n",
    "for i in range(conv_depth):\n",
    "    conv_dim_reduction = kernel_sizes[i]-1-paddings[i]*2\n",
    "    assert (input_size - conv_dim_reduction) % (strides[i]*poolings[i]) == 0\n",
    "    conv_size.append(int((input_size - conv_dim_reduction)/strides[i]/poolings[i]))\n",
    "    input_size = conv_size[i]\n",
    "    print(\"Conv layer {} has output size {} and {} channels.\".format(i, conv_size[i], channels[i]))\n",
    "\n",
    "conv_output_size = conv_size[-1]*channels[-1]\n",
    "\n",
    "\n",
    "assert len(features) >= lin_depth\n",
    "assert len(lin_batch_norms) >= lin_depth\n",
    "assert len(lin_dropouts) >= lin_depth\n",
    "for dropout in lin_dropouts:\n",
    "    assert 0 <= dropout and dropout <= 1, \"Dropout must be between 0 and 1.\"\n",
    "for i in range(lin_depth):\n",
    "    print(\"Lin layer {} has output size {}.\".format(i, features[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        in_channels = 1\n",
    "        for i in range(conv_depth):\n",
    "            conv = nn.Conv1d(in_channels=in_channels, out_channels=channels[i], kernel_size=kernel_sizes[i], stride=strides[i], padding=paddings[i])\n",
    "            in_channels = channels[i]\n",
    "            pool = nn.MaxPool1d(poolings[i])\n",
    "            batchnorm = nn.BatchNorm1d(channels[i]) if (conv_batch_norms[i]) else nn.Identity()\n",
    "            dropout = nn.Dropout(p=conv_dropouts[i])\n",
    "\n",
    "            self.convs.append(nn.ModuleList([conv, pool, batchnorm, dropout]))\n",
    "        \n",
    "        self.lins = nn.ModuleList()\n",
    "        in_features = conv_output_size\n",
    "        for i in range(lin_depth):\n",
    "            lin = nn.Linear(in_features=in_features, out_features=features[i])\n",
    "            in_features = features[i]\n",
    "            batchnorm = nn.BatchNorm1d(features[i]) if (lin_batch_norms[i]) else nn.Identity()\n",
    "            dropout = nn.Dropout(p=lin_dropouts[i])\n",
    "\n",
    "            self.lins.append(nn.ModuleList([lin, batchnorm, dropout]))\n",
    "\n",
    "        self.lin_out = nn.Linear(in_features=in_features, out_features=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        for conv, pool, batchnorm, dropout in self.convs:\n",
    "            x = conv(x)\n",
    "            x = pool(x)\n",
    "            x = nn_func.relu(x)\n",
    "            x = batchnorm(x)\n",
    "            x = dropout(x)\n",
    "\n",
    "        x = x.flatten(1)\n",
    "\n",
    "        for lin, batchnorm, dropout in self.lins:\n",
    "            x = lin(x)\n",
    "            x = nn_func.relu(x)\n",
    "            x = batchnorm(x)\n",
    "            x = dropout(x)\n",
    "            \n",
    "        return self.lin_out(x).unsqueeze(1)\n",
    "\n",
    "net = Net()\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-2\n",
    "WEIGHT_DECAY = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  \n",
    "\n",
    "# weight_decay is equal to L2 regularization\n",
    "optimizer = optim.AdamW(net.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_torch(x):\n",
    "    variable = Variable(torch.from_numpy(x))\n",
    "    if use_cuda:\n",
    "        variable = variable.cuda()\n",
    "    return variable\n",
    "\n",
    "def test_net(net, validation_loader, criterion):\n",
    "    was_training = net.training\n",
    "    net.eval()\n",
    "    num_iterations = 100\n",
    "    total_loss = 0\n",
    "    for data_point, frequency in itertools.islice(validation_loader, num_iterations):\n",
    "        data_point = data_point.to(device)\n",
    "        frequency = frequency.to(device)\n",
    "        output = net(data_point)\n",
    "        total_loss += criterion(output, frequency)\n",
    "    net.train(mode=was_training)\n",
    "    return total_loss/num_iterations\n",
    "\n",
    "def manual_test(net, validation_generator):\n",
    "    was_training = net.training\n",
    "    net.eval()\n",
    "    num_iterations = 5\n",
    "    for data_point in validation_generator.next_n(num_iterations):\n",
    "        samples = to_torch(data_point.get_samples()).unsqueeze(0)\n",
    "        freq_map = to_torch(np.array([data_point.get_frequency_map()])).unsqueeze(0)\n",
    "        output = net(samples)\n",
    "        target_frequency = parameters.map_to_frequency(freq_map.item())\n",
    "        output_frequency = parameters.map_to_frequency(output.item())\n",
    "        print(\"Frequency: {:.2f} Output: {:.2f} Cent diff: {:.2f}\".format(target_frequency, output_frequency, aus.cent_diff(target_frequency, output_frequency)))\n",
    "    net.train(mode=was_training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BATCHES = 2000\n",
    "EVAL_EVERY = 200\n",
    "\n",
    "\n",
    "manual_test(net, validation_generator)\n",
    "\n",
    "net.train()\n",
    "\n",
    "for i, (data_point, frequency) in enumerate(itertools.islice(training_loader, NUM_BATCHES)):\n",
    "    if i%EVAL_EVERY == 0:\n",
    "        print(f\"Loss at iteration {i}: {test_net(net, validation_loader, criterion)}\")\n",
    "    data_point = data_point.to(device)\n",
    "    frequency = frequency.to(device)\n",
    "    output = net(data_point)\n",
    "    loss = criterion(output, frequency)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"Loss at iteration {NUM_BATCHES}: {test_net(net, validation_loader, criterion)}\")\n",
    "manual_test(net, validation_generator)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
